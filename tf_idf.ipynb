{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spark examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "from math import log\n",
    "\n",
    "def get_word_length(text):\n",
    "    \n",
    "    lines = sc.textFile(text)\n",
    "    return lines.map(lambda s: len(s.split())).reduce(lambda a, b: a + b)\n",
    "\n",
    "def tf(text):\n",
    "    n = get_word_length(text)\n",
    "    lines = sc.textFile(text, 1)\n",
    "    counts = lines.flatMap(lambda x: x.split(' ')) \\\n",
    "        .map(lambda x: (x, 1./n)).reduceByKey(add)\n",
    "    output = counts.collect()\n",
    "    return dict(output)\n",
    "\n",
    "def inverted_tf(word, texts):\n",
    "    binary_docs = []\n",
    "    for t in texts:\n",
    "        lines = sc.textFile(text)\n",
    "        has_word = lines.filter(lambda x: word in x).count()\n",
    "        binary_docs.append(has_word)\n",
    "    return sum(binary_docs)\n",
    "\n",
    "def idf(word, texts):\n",
    "    return log(float(len(texts)) / (1 + inverted_tf(word, texts)))\n",
    "\n",
    "def tfidf(word, text, texts):\n",
    "    return tf(text).get(word, 0) * idf(word, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = 'd_0'\n",
    "texts = [\"data_files/d_{}\".format(str(i)) for i in range(10)]\n",
    "sample_words =  ['and', 'set', 'says', 'give', 'it', 'cowhide', \\\n",
    "                 'a-growling', 'tore', 'minute,', 'aint', 'there', \\\n",
    "                 'better', 'then', 'you', 'dandy', 'though', 'a', 'he', \\\n",
    "                 'sweet-scented', 'a-mumbling', 'up', 'something']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf of and is -0.00465113677445\n",
      "tf-idf of set is -0.000142965269706\n",
      "tf-idf of says is -8.57791618239e-05\n",
      "tf-idf of give is -0.000114372215765\n",
      "tf-idf of it is -0.00138199760716\n",
      "tf-idf of cowhide is -9.53101798043e-06\n",
      "tf-idf of a-growling is -9.53101798043e-06\n",
      "tf-idf of tore is -9.53101798043e-06\n",
      "tf-idf of minute, is -3.81240719217e-05\n",
      "tf-idf of aint is 0.0\n",
      "tf-idf of there is -0.000295461557393\n",
      "tf-idf of better is -2.85930539413e-05\n",
      "tf-idf of then is -0.000400302755178\n",
      "tf-idf of you is -0.000810136528337\n",
      "tf-idf of dandy is -0.0\n",
      "tf-idf of though is -5.71861078826e-05\n",
      "tf-idf of a is -0.00246853365693\n",
      "tf-idf of he is -0.00150590084091\n",
      "tf-idf of sweet-scented is -9.53101798043e-06\n",
      "tf-idf of a-mumbling is -9.53101798043e-06\n",
      "tf-idf of up is -0.000524205988924\n",
      "tf-idf of something is -0.000123903233746\n"
     ]
    }
   ],
   "source": [
    "for s in sample_words:\n",
    "    print \"tf-idf of {0} is {1}\".format(s, tfidf(s, text, texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so using texts that are all from the same corpus doesn't give the best demonstration of TF-IDF. But it's nice to do some neat map-reducing in any case.\n",
    "\n",
    "Will come back when I find some cool texts to demonstrate on further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is straight from the docs, but I'll be making some modifications soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.142999\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "from random import random\n",
    "from operator import add\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "def pi():\n",
    "    \n",
    "    partitions = 3\n",
    "    n = 1000000 * partitions\n",
    "\n",
    "    def f(_):\n",
    "        x = random() * 2 - 1\n",
    "        y = random() * 2 - 1\n",
    "        return 1 if x ** 2 + y ** 2 < 1 else 0\n",
    "\n",
    "    count = sc.parallelize(range(1, n + 1), partitions).map(f).reduce(add)\n",
    "    print(\"Pi is roughly %f\" % (4.0 * count / n))\n",
    "\n",
    "    sc.stop()\n",
    "\n",
    "pi()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
