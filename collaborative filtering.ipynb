{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Book Crossing data set is widely used for collaborative filtering, and consists of users' rating of around 100k users' ratings of around a million books, identified by their ISBN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We'll want to clean this up a little. In particular, I like to turn categoricals into values between 0 and N, where N is the number of distinct values for the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map users and isbns into reasonable values\n",
    "\n",
    "def map_to_N(feature, new_name):\n",
    "\n",
    "    users = ratings[feature].unique()\n",
    "    n_users = len(users)\n",
    "    userdict = dict(zip(users, range(n_users)))\n",
    "    ratings[new_name] = ratings[feature].map(lambda x: userdict[x])\n",
    "    \n",
    "map_to_N(\"User-ID\", \"User_idx\")\n",
    "map_to_N(\"ISBN\", \"ISBN_idx\")\n",
    "\n",
    "# and drop old columns\n",
    "ratings = ratings[['User_idx', 'ISBN_idx', 'Book-Rating']]\n",
    "\n",
    "unknown = ratings[ratings['Book-Rating'] == 0]\n",
    "known = ratings[ratings['Book-Rating'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You'll want to make sure you import SparkContext and SparkConf before going any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindata = sc.textFile(\"train_ratings\")\n",
    "train_ratings = traindata.map(lambda l: l.split(',')).map(lambda m: Rating(int(m[0]), int(m[1]), int(m[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loaded, it's simple to use MLLib's built in ALS to train a model. A few parameters you can configure are:\n",
    "* numBlocks, how many computations you want to run in parallel\n",
    "* rank, the number of latent factors, and \n",
    "* iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank = 5; iterations = 10\n",
    "model = ALS.train(train_ratings, rank=rank, iterations=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate our model on a portion of our data to see how accurate our predictions were. If all goes well, we can fill in our \"unknown\" matrix with predictions from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = sc.textFile(\"test_ratings\").map(lambda l: l.split(','))\n",
    "all_fields = test_data.map(lambda p: ((int(p[0]), int(p[1])), int(p[2])))\n",
    "user_and_product = test_data.map(lambda p: (p[0], p[1]))\n",
    "predictions = model.predictAll(user_and_product).map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratesAndPreds = all_fields.join(predictions)\n",
    "diffs = ratesAndPreds.map(lambda r: (r[1][1] - r[1][0])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.797772454855\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "mse = diffs.reduce(add) / diffs.count()\n",
    "print \"RMSE: \", sqrt(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
